{
 "cells": [
  {
   "cell_type": "code",
   "id": "67c6c150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T03:49:28.975213Z",
     "start_time": "2025-09-21T03:45:22.171781Z"
    }
   },
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ë¸Œë¼ìš°ì € ì˜µì…˜ ì„¤ì •\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")  # ë¡œê·¸ì¸í•´ì•¼ í•˜ë¯€ë¡œ êº¼ë‘ \n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# ë“œë¼ì´ë²„ ì‹¤í–‰\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# ë¡œê·¸ì¸ ë° í•„í„° í›„ ê²€ìƒ‰ í˜ì´ì§€ ìˆ˜ë™ ì ‘ì†\n",
    "print(\"ğŸ” ë¸Œë¼ìš°ì €ê°€ ì—´ë¦½ë‹ˆë‹¤. ProQuestì— ë¡œê·¸ì¸í•˜ê³ , í•„í„°ì™€ ê²€ìƒ‰ì–´ ì„¤ì • í›„ ì›í•˜ëŠ” ê²€ìƒ‰ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”.\")\n",
    "driver.get(\"https://www.proquest.com/\")\n",
    "input(\"âœ… í•„í„° ì ìš© ì™„ë£Œ í›„ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "MAX_PAGES = 80  # ì›í•˜ëŠ” í˜ì´ì§€ ìˆ˜ë§Œí¼ ë°˜ë³µ\n",
    "for page in range(1, MAX_PAGES + 1):\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    links = soup.select('div.resultHeader div h3 a')\n",
    "\n",
    "    print(f\"ğŸ“„ í˜ì´ì§€ {page}ì—ì„œ {len(links)}ê°œ ë§í¬ ìˆ˜ì§‘\")\n",
    "\n",
    "    for link in links:\n",
    "        title = link.get_text(strip=True)\n",
    "        href = link.get('href')\n",
    "        full_url = \"https://www.proquest.com\" + href if href.startswith(\"/\") else href\n",
    "\n",
    "        results.append({\n",
    "            'title': title,\n",
    "            'link': full_url\n",
    "        })\n",
    "\n",
    "    # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ ì‹œë„\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"updateForm\"]/nav/ul/li[9]/a')\n",
    "        if next_button.is_enabled():\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            print(\"â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\")\n",
    "            time.sleep(4)\n",
    "        else:\n",
    "            print(\"ğŸš« ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "            break\n",
    "    except NoSuchElementException:\n",
    "        print(\"âŒ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        break\n",
    "    except ElementClickInterceptedException:\n",
    "        print(\"âš ï¸ ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨. ìŠ¤í¬ë¡¤ í›„ ì¬ì‹œë„\")\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "# CSV ì €ì¥\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"proquest_wallstreet.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… ì™„ë£Œ: ì´ {len(df)}ê°œì˜ í•­ëª©ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "driver.quit()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Academia-Industry-gap-analysis/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ë¸Œë¼ìš°ì €ê°€ ì—´ë¦½ë‹ˆë‹¤. ProQuestì— ë¡œê·¸ì¸í•˜ê³ , í•„í„°ì™€ ê²€ìƒ‰ì–´ ì„¤ì • í›„ ì›í•˜ëŠ” ê²€ìƒ‰ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”.\n",
      "ğŸ“„ í˜ì´ì§€ 1ì—ì„œ 20ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\n",
      "ğŸ“„ í˜ì´ì§€ 2ì—ì„œ 20ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\n",
      "ğŸ“„ í˜ì´ì§€ 3ì—ì„œ 20ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\n",
      "ğŸ“„ í˜ì´ì§€ 4ì—ì„œ 20ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\n",
      "ğŸ“„ í˜ì´ì§€ 5ì—ì„œ 20ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\n",
      "ğŸ“„ í˜ì´ì§€ 6ì—ì„œ 20ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\n",
      "ğŸ“„ í˜ì´ì§€ 7ì—ì„œ 20ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\n",
      "ğŸ“„ í˜ì´ì§€ 8ì—ì„œ 20ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™...\n",
      "ğŸ“„ í˜ì´ì§€ 9ì—ì„œ 4ê°œ ë§í¬ ìˆ˜ì§‘\n",
      "âŒ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "âœ… ì™„ë£Œ: ì´ 164ê°œì˜ í•­ëª©ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2d312dfa",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-21T03:49:49.399204Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# í¬ë¡¬ ì˜µì…˜ ì„¤ì •\n",
    "options = Options()\n",
    "# options.add_argument('--headless')  # í•„ìš” ì‹œ ì£¼ì„ í•´ì œ\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "\n",
    "# ë“œë¼ì´ë²„ ì‹¤í–‰\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('proquest_wallstreet.csv')\n",
    "# df = df.head(20)  # í…ŒìŠ¤íŠ¸ë¡œ ì¼ë¶€ë§Œ ì‹¤í–‰\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    url = row['link']\n",
    "    title = row['title']\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # âœ… URLì—ì„œ docview ID ì¶”ì¶œ\n",
    "        doc_id_match = re.search(r'/docview/(\\d+)', url)\n",
    "        doc_id = doc_id_match.group(1) if doc_id_match else ''\n",
    "        mstar_id = f\"MSTAR_{doc_id}\" if doc_id else ''\n",
    "\n",
    "        # âœ… ë³¸ë¬¸(Content)\n",
    "        content = ''\n",
    "        xpaths_content = [\n",
    "            f'//*[@id=\"fulltext_field_{mstar_id}\"]/div/root/text/p' if mstar_id else '',\n",
    "            '//*[@id=\"fullTextZone\"]//p',\n",
    "            '//*[@id=\"main-content\"]//p',\n",
    "            '//*[@id=\"companionColumn-0\"]//p',\n",
    "        ]\n",
    "        for xp in xpaths_content:\n",
    "            if not xp:\n",
    "                continue\n",
    "            try:\n",
    "                paragraphs = driver.find_elements(By.XPATH, xp)\n",
    "                if paragraphs:\n",
    "                    content = '\\n'.join(p.text.strip() for p in paragraphs if p.text.strip())\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # âœ… ë‚ ì§œ(Date): BeautifulSoupë¡œ strong + í˜•ì œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ\n",
    "        date_text = ''\n",
    "        try:\n",
    "            strong_tag = soup.find('strong', string=lambda s: s and ';' in s)\n",
    "            if strong_tag and strong_tag.next_sibling:\n",
    "                raw = strong_tag.next_sibling.strip()\n",
    "                match = re.search(r'\\d{2} \\w{3} \\d{4}', raw)  # \"04 Feb 2025\"\n",
    "                if match:\n",
    "                    date_text = match.group()\n",
    "                else:\n",
    "                    date_text = raw\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # âœ… ë¯¸ë””ì–´(Media)\n",
    "        media = ''\n",
    "        xpaths_media = [\n",
    "            f'//*[@id=\"pubPopoverTrigger-{mstar_id}\"]/span' if mstar_id else '',\n",
    "            '//*[@id=\"bibSource\"]/span',\n",
    "            '//div[@class=\"publicationTitle\"]',\n",
    "            '//div[@class=\"bibSource\"]',\n",
    "            '//span[@class=\"publicationTitle\"]',\n",
    "        ]\n",
    "        for xp in xpaths_media:\n",
    "            if not xp:\n",
    "                continue\n",
    "            try:\n",
    "                media_el = driver.find_element(By.XPATH, xp)\n",
    "                media = media_el.text.strip().split(';')[0]\n",
    "                if media:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        results.append({\n",
    "            'title': title,\n",
    "            'link': url,\n",
    "            'date': date_text,\n",
    "            'media': media,\n",
    "            'content': content\n",
    "        })\n",
    "\n",
    "        print(f\"[{idx+1}] âœ… ì™„ë£Œ: {title[:40]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{idx+1}] âŒ ì‹¤íŒ¨: {url} â†’ {e}\")\n",
    "        results.append({\n",
    "            'title': title,\n",
    "            'link': url,\n",
    "            'date': '',\n",
    "            'media': '',\n",
    "            'content': ''\n",
    "        })\n",
    "\n",
    "# ì €ì¥\n",
    "output_df = pd.DataFrame(results, columns=['title', 'link', 'date', 'media', 'content'])\n",
    "output_df.to_csv('wallstreet_content.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"ğŸ“„ ì €ì¥ ì™„ë£Œ: wallstreet_content.csv\")\n",
    "\n",
    "driver.quit()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85d62b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>media</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArtificialIntelligence(A Special Report) --- H...</td>\n",
       "      <td>https://www.proquest.com/docview/3132486081/2B...</td>\n",
       "      <td>25 Nov 2024</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>The current generation of college students is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArtificialIntelligence(A Special Report) --- T...</td>\n",
       "      <td>https://www.proquest.com/docview/3132486071/2B...</td>\n",
       "      <td>25 Nov 2024</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>ChatGPT is barely two years old. And yet it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArtificialIntelligence(A Special Report) --- F...</td>\n",
       "      <td>https://www.proquest.com/docview/3162691166/2B...</td>\n",
       "      <td>03 Feb 2025</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>The race for AI dominance launched a stampede ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crunchbase UsesArtificialIntelligenceTo Predic...</td>\n",
       "      <td>https://www.proquest.com/docview/3168537629/2B...</td>\n",
       "      <td>20 Feb 2025</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Crunchbase, the firm best known for its startu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On the Clock: Bosses' Mental Fitness Set for A...</td>\n",
       "      <td>https://www.proquest.com/docview/3096788378/2B...</td>\n",
       "      <td>26 Aug 2024</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Bosses already live in fear that a verbal miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EXCHANGE --- The Rundown on Building an AI Sup...</td>\n",
       "      <td>https://www.proquest.com/docview/3191507034/2B...</td>\n",
       "      <td>19 Apr 2025</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>President Trump enthused on social media this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ArtificialIntelligence(A Special Report) --- H...</td>\n",
       "      <td>https://www.proquest.com/docview/3132486040/2B...</td>\n",
       "      <td>25 Nov 2024</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Artificial intelligence is poised to transform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ArtificialIntelligence(A Special Report) --- H...</td>\n",
       "      <td>https://www.proquest.com/docview/3162691094/2B...</td>\n",
       "      <td>03 Feb 2025</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>You can't stop an AI chatbot from sometimes ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Future of Everything: TheArtificialIntelli...</td>\n",
       "      <td>https://www.proquest.com/docview/3171573768/2B...</td>\n",
       "      <td>27 Feb 2025</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>In a large, brightly-lit warehouse in Flowery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Future of Everything: TheArtificialIntelli...</td>\n",
       "      <td>https://www.proquest.com/docview/3098087388/2B...</td>\n",
       "      <td>29 Aug 2024</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>A plate of food has been set before you -- per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Future of Everything: TheArtificialIntelli...</td>\n",
       "      <td>https://www.proquest.com/docview/3171573764/2B...</td>\n",
       "      <td>27 Feb 2025</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Deep under the sea, pipelines and cables carry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rising Data Center Costs Linked ToArtificialIn...</td>\n",
       "      <td>https://www.proquest.com/docview/2836987360/2B...</td>\n",
       "      <td>.Â 14 July 2023: B.4.</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Runaway demand for artificial intelligence is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Boom inArtificialIntelligenceHelps Lift Tech-S...</td>\n",
       "      <td>https://www.proquest.com/docview/2833514990/2B...</td>\n",
       "      <td>.Â 06 July 2023: A.1.</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Excitement over artificial intelligence is pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Biotech Joins AI-Fueled Rally --- Investors be...</td>\n",
       "      <td>https://www.proquest.com/docview/2842338996/2B...</td>\n",
       "      <td>.Â 27 July 2023: B.11.</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Healthcare shares have struggled this year, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AI Spurs New Cybersecurity Threats --- Hackers...</td>\n",
       "      <td>https://www.proquest.com/docview/2873154470/2B...</td>\n",
       "      <td>06 Oct 2023</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Hackers are using AI and encryption in new way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ArtificialIntelligence: Finance Chiefs Tackle ...</td>\n",
       "      <td>https://www.proquest.com/docview/2973859850/2B...</td>\n",
       "      <td>25 Mar 2024</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Finance chiefs are making sure their companies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>U.S. News: OpenAI's New CEO at Center of AI Dr...</td>\n",
       "      <td>https://www.proquest.com/docview/2891939812/2B...</td>\n",
       "      <td>21 Nov 2023</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Emmett Shear's sudden appointment as OpenAI CE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ArtificialIntelligence(A Special Report) --- S...</td>\n",
       "      <td>https://www.proquest.com/docview/2887205702/2B...</td>\n",
       "      <td>09 Nov 2023</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Kevin Lisle, who has been teaching high-school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ArtificialIntelligence(A Special Report) --- C...</td>\n",
       "      <td>https://www.proquest.com/docview/2887205653/2B...</td>\n",
       "      <td>09 Nov 2023</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>Recyclers across the U.S. are struggling, hurt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ArtificialIntelligence(A Special Report) --- G...</td>\n",
       "      <td>https://www.proquest.com/docview/2917151619/2B...</td>\n",
       "      <td>22 Jan 2024</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>President Biden issued an executive order late...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   ArtificialIntelligence(A Special Report) --- H...   \n",
       "1   ArtificialIntelligence(A Special Report) --- T...   \n",
       "2   ArtificialIntelligence(A Special Report) --- F...   \n",
       "3   Crunchbase UsesArtificialIntelligenceTo Predic...   \n",
       "4   On the Clock: Bosses' Mental Fitness Set for A...   \n",
       "5   EXCHANGE --- The Rundown on Building an AI Sup...   \n",
       "6   ArtificialIntelligence(A Special Report) --- H...   \n",
       "7   ArtificialIntelligence(A Special Report) --- H...   \n",
       "8   The Future of Everything: TheArtificialIntelli...   \n",
       "9   The Future of Everything: TheArtificialIntelli...   \n",
       "10  The Future of Everything: TheArtificialIntelli...   \n",
       "11  Rising Data Center Costs Linked ToArtificialIn...   \n",
       "12  Boom inArtificialIntelligenceHelps Lift Tech-S...   \n",
       "13  Biotech Joins AI-Fueled Rally --- Investors be...   \n",
       "14  AI Spurs New Cybersecurity Threats --- Hackers...   \n",
       "15  ArtificialIntelligence: Finance Chiefs Tackle ...   \n",
       "16  U.S. News: OpenAI's New CEO at Center of AI Dr...   \n",
       "17  ArtificialIntelligence(A Special Report) --- S...   \n",
       "18  ArtificialIntelligence(A Special Report) --- C...   \n",
       "19  ArtificialIntelligence(A Special Report) --- G...   \n",
       "\n",
       "                                                 link                   date  \\\n",
       "0   https://www.proquest.com/docview/3132486081/2B...            25 Nov 2024   \n",
       "1   https://www.proquest.com/docview/3132486071/2B...            25 Nov 2024   \n",
       "2   https://www.proquest.com/docview/3162691166/2B...            03 Feb 2025   \n",
       "3   https://www.proquest.com/docview/3168537629/2B...            20 Feb 2025   \n",
       "4   https://www.proquest.com/docview/3096788378/2B...            26 Aug 2024   \n",
       "5   https://www.proquest.com/docview/3191507034/2B...            19 Apr 2025   \n",
       "6   https://www.proquest.com/docview/3132486040/2B...            25 Nov 2024   \n",
       "7   https://www.proquest.com/docview/3162691094/2B...            03 Feb 2025   \n",
       "8   https://www.proquest.com/docview/3171573768/2B...            27 Feb 2025   \n",
       "9   https://www.proquest.com/docview/3098087388/2B...            29 Aug 2024   \n",
       "10  https://www.proquest.com/docview/3171573764/2B...            27 Feb 2025   \n",
       "11  https://www.proquest.com/docview/2836987360/2B...   .Â 14 July 2023: B.4.   \n",
       "12  https://www.proquest.com/docview/2833514990/2B...   .Â 06 July 2023: A.1.   \n",
       "13  https://www.proquest.com/docview/2842338996/2B...  .Â 27 July 2023: B.11.   \n",
       "14  https://www.proquest.com/docview/2873154470/2B...            06 Oct 2023   \n",
       "15  https://www.proquest.com/docview/2973859850/2B...            25 Mar 2024   \n",
       "16  https://www.proquest.com/docview/2891939812/2B...            21 Nov 2023   \n",
       "17  https://www.proquest.com/docview/2887205702/2B...            09 Nov 2023   \n",
       "18  https://www.proquest.com/docview/2887205653/2B...            09 Nov 2023   \n",
       "19  https://www.proquest.com/docview/2917151619/2B...            22 Jan 2024   \n",
       "\n",
       "                  media                                            content  \n",
       "0   Wall Street Journal  The current generation of college students is ...  \n",
       "1   Wall Street Journal  ChatGPT is barely two years old. And yet it's ...  \n",
       "2   Wall Street Journal  The race for AI dominance launched a stampede ...  \n",
       "3   Wall Street Journal  Crunchbase, the firm best known for its startu...  \n",
       "4   Wall Street Journal  Bosses already live in fear that a verbal miss...  \n",
       "5   Wall Street Journal  President Trump enthused on social media this ...  \n",
       "6   Wall Street Journal  Artificial intelligence is poised to transform...  \n",
       "7   Wall Street Journal  You can't stop an AI chatbot from sometimes ha...  \n",
       "8   Wall Street Journal  In a large, brightly-lit warehouse in Flowery ...  \n",
       "9   Wall Street Journal  A plate of food has been set before you -- per...  \n",
       "10  Wall Street Journal  Deep under the sea, pipelines and cables carry...  \n",
       "11  Wall Street Journal  Runaway demand for artificial intelligence is ...  \n",
       "12  Wall Street Journal  Excitement over artificial intelligence is pro...  \n",
       "13  Wall Street Journal  Healthcare shares have struggled this year, bu...  \n",
       "14  Wall Street Journal  Hackers are using AI and encryption in new way...  \n",
       "15  Wall Street Journal  Finance chiefs are making sure their companies...  \n",
       "16  Wall Street Journal  Emmett Shear's sudden appointment as OpenAI CE...  \n",
       "17  Wall Street Journal  Kevin Lisle, who has been teaching high-school...  \n",
       "18  Wall Street Journal  Recyclers across the U.S. are struggling, hurt...  \n",
       "19  Wall Street Journal  President Biden issued an executive order late...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('wallstreet_content.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f8d34",
   "metadata": {},
   "source": [
    "# ë¹ˆ ì½˜í…ì¸  ì¶”ê°€ìˆ˜ì§‘ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ff36d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ìˆ˜ì§‘í•  ë¬¸ì„œ ìˆ˜: 20\n",
      "[357] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: EXCHANGE --- Markets & Finance: Aflac Sa...\n",
      "[358] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: OpenAI Aims for $90 Billion Value With S...\n",
      "[359] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Microsoft CEO Says Google's Tactics Hurt...\n",
      "[360] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Business & Finance...\n",
      "[361] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: U.S. News: FBI Investigates Chief-of-Sta...\n",
      "[362] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Apple to Source More Phones From India -...\n",
      "[363] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Microsoft To Invest In U.A.E. AI Firm...\n",
      "[364] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: World News: Lebanon Takes Steps to Loose...\n",
      "[396] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Business & Finance...\n",
      "[397] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Business & Finance...\n",
      "[398] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Business & Finance...\n",
      "[399] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Business & Finance...\n",
      "[400] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Business & Finance...\n",
      "[401] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Markets: Stock Spotlight...\n",
      "[402] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Former Binance.US CEO Has New Firm...\n",
      "[403] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Markets: Stock Spotlight...\n",
      "[404] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Markets & Finance: Stock Spotlight...\n",
      "[405] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Business & Finance...\n",
      "[406] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Business & Finance...\n",
      "[407] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: Markets: Stock Spotlight...\n",
      "ğŸ“„ ì €ì¥ ì™„ë£Œ: wallstreet_content.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# â–¶ ê¸°ì¡´ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "existing_df = pd.read_csv('wallstreet_content.csv')\n",
    "\n",
    "# â–¶ contentê°€ ë¹ˆ rowë§Œ í•„í„°ë§\n",
    "empty_content_df = existing_df[existing_df['content'].isna() | (existing_df['content'].str.strip() == '')]\n",
    "\n",
    "empty_content_df=empty_content_df.head(20)\n",
    "\n",
    "if empty_content_df.empty:\n",
    "    print(\"âœ… ëª¨ë“  contentê°€ ì´ë¯¸ ìˆ˜ì§‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ ìˆ˜ì§‘í•  ë¬¸ì„œ ìˆ˜: {len(empty_content_df)}\")\n",
    "\n",
    "    # â–¶ í¬ë¡¬ ì˜µì…˜ ì„¤ì •\n",
    "    options = Options()\n",
    "    # options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    # â–¶ ë“œë¼ì´ë²„ ì‹¤í–‰\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, row in empty_content_df.iterrows():\n",
    "        url = row['link']\n",
    "        title = row['title']\n",
    "\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(3)\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # âœ… URLì—ì„œ docview ID ì¶”ì¶œ\n",
    "            doc_id_match = re.search(r'/docview/(\\d+)', url)\n",
    "            doc_id = doc_id_match.group(1) if doc_id_match else ''\n",
    "            mstar_id = f\"MSTAR_{doc_id}\" if doc_id else ''\n",
    "\n",
    "            # âœ… ë³¸ë¬¸(Content)\n",
    "            content = ''\n",
    "            xpaths_content = [\n",
    "                f'//*[@id=\"fulltext_field_{mstar_id}\"]/div/root/text/p' if mstar_id else '',\n",
    "                '//*[@id=\"fullTextZone\"]//p',\n",
    "                '//*[@id=\"main-content\"]//p',\n",
    "                '//*[@id=\"companionColumn-0\"]//p',\n",
    "            ]\n",
    "            for xp in xpaths_content:\n",
    "                if not xp:\n",
    "                    continue\n",
    "                try:\n",
    "                    paragraphs = driver.find_elements(By.XPATH, xp)\n",
    "                    if paragraphs:\n",
    "                        content = '\\n'.join(p.text.strip() for p in paragraphs if p.text.strip())\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # âœ… ë‚ ì§œ(Date): BeautifulSoupë¡œ strong + í˜•ì œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ\n",
    "            date_text = row['date']  # ê¸°ë³¸ê°’: ê¸°ì¡´ ê°’ ìœ ì§€\n",
    "            try:\n",
    "                strong_tag = soup.find('strong', string=lambda s: s and ';' in s)\n",
    "                if strong_tag and strong_tag.next_sibling:\n",
    "                    raw = strong_tag.next_sibling.strip()\n",
    "                    match = re.search(r'\\d{2} \\w{3} \\d{4}', raw)\n",
    "                    if match:\n",
    "                        date_text = match.group()\n",
    "                    else:\n",
    "                        date_text = raw\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # âœ… ë¯¸ë””ì–´(Media)\n",
    "            media = row['media']  # ê¸°ë³¸ê°’: ê¸°ì¡´ ê°’ ìœ ì§€\n",
    "            xpaths_media = [\n",
    "                f'//*[@id=\"pubPopoverTrigger-{mstar_id}\"]/span' if mstar_id else '',\n",
    "                '//*[@id=\"bibSource\"]/span',\n",
    "                '//div[@class=\"publicationTitle\"]',\n",
    "                '//div[@class=\"bibSource\"]',\n",
    "                '//span[@class=\"publicationTitle\"]',\n",
    "            ]\n",
    "            for xp in xpaths_media:\n",
    "                if not xp:\n",
    "                    continue\n",
    "                try:\n",
    "                    media_el = driver.find_element(By.XPATH, xp)\n",
    "                    media = media_el.text.strip().split(';')[0]\n",
    "                    if media:\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # âœ… ê²°ê³¼ ì €ì¥\n",
    "            existing_df.loc[idx, 'content'] = content\n",
    "            existing_df.loc[idx, 'date'] = date_text\n",
    "            existing_df.loc[idx, 'media'] = media\n",
    "\n",
    "            print(f\"[{idx+1}] âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {title[:40]}...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{idx+1}] âŒ ì‹¤íŒ¨: {url} â†’ {e}\")\n",
    "\n",
    "    # â–¶ CSV ë®ì–´ì“°ê¸° ì €ì¥\n",
    "    existing_df.to_csv('wallstreet_content.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"ğŸ“„ ì €ì¥ ì™„ë£Œ: wallstreet_content.csv\")\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "455ae27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1593 entries, 0 to 1592\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    1593 non-null   object\n",
      " 1   link     1593 non-null   object\n",
      " 2   date     962 non-null    object\n",
      " 3   media    962 non-null    object\n",
      " 4   content  962 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 62.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test=pd.read_csv('wallstreet_content.csv')\n",
    "test.info() #ê¸°ì¡´ 962ê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58faaf53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
