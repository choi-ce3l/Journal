import os
import time
import random
import pandas as pd
import undetected_chromedriver as uc
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, WebDriverException

# ===== ì‚¬ìš©ì í™˜ê²½ =====
vol_from = 199 # 164 ~ 199
vol_to = 199 # 176ë¶€í„° í•´ì•¼í•¨

SAVE_DIR = r"/Users/choihj/PycharmProjects/Journal/Data/Academia/DSS"
os.makedirs(SAVE_DIR, exist_ok=True)
OUTPUT_CSV = os.path.join(SAVE_DIR, f"dss_vol_{vol_from}_to_{vol_to}.csv")
HEADLESS = False
MAX_RETRIES = 1  # ì¬ì‹œë„ íšŸìˆ˜


# ===== Volumeë³„ ë‚ ì§œ ë§¤í•‘ =====
def get_date_by_volume(volume):
    """Volume ë²ˆí˜¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚ ì§œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    start_year = 2023
    start_month = 1
    start_volume = 164

    months_diff = volume - start_volume
    total_months = (start_year - 2000) * 12 + start_month + months_diff
    year = 2000 + (total_months - 1) // 12
    month = ((total_months - 1) % 12) + 1

    return f"{year}-{month:02d}"


# ===== ìœ í‹¸ =====
def random_wait(a=1.0, b=3.0):
    time.sleep(random.uniform(a, b))


def get_driver():
    """ë“œë¼ì´ë²„ ìƒì„± ë° ì„¤ì •"""
    opts = uc.ChromeOptions()
    if HEADLESS:
        opts.add_argument("--headless=new")
    opts.add_argument("--window-size=1920,1080")  # ë” í° ì°½ í¬ê¸°
    opts.add_argument("--disable-blink-features=AutomationControlled")
    opts.add_argument("--disable-infobars")
    opts.add_argument("--disable-extensions")
    opts.add_argument("--disable-popup-blocking")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-gpu")  # GPU ê°€ì† ë¹„í™œì„±í™”
    opts.add_argument(
        "user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    try:
        drv = uc.Chrome(options=opts)
        drv.set_page_load_timeout(60)  # í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        try:
            drv.execute_cdp_cmd(
                "Page.addScriptToEvaluateOnNewDocument",
                {"source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"}
            )
        except WebDriverException:
            pass
        return drv
    except Exception as e:
        print(f"âŒ ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {e}")
        raise


def safe_get_url(driver, url, max_retries=MAX_RETRIES):
    """URL ì ‘ì† ì¬ì‹œë„ ë¡œì§"""
    for attempt in range(max_retries):
        try:
            driver.get(url)
            random_wait(2, 3)
            return True
        except TimeoutException:
            print(f"â±ï¸ íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{max_retries}): {url}")
            if attempt < max_retries - 1:
                random_wait(3, 5)
            else:
                return False
        except WebDriverException as e:
            print(f"ğŸš§ WebDriver ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                random_wait(5, 8)
            else:
                return False
    return False


def accept_cookies(driver):
    """ì¿ í‚¤ ìˆ˜ë½"""
    try:
        cookie_btn = WebDriverWait(driver, 5).until(
            EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler"))
        )
        cookie_btn.click()
        print("âœ… ì¿ í‚¤ ìˆ˜ë½ ì™„ë£Œ")
        random_wait(1, 2)
        return True
    except Exception:
        print("â„¹ï¸ ì¿ í‚¤ ìˆ˜ë½ ë²„íŠ¼ ì—†ìŒ")
        return False


def extract_text(el):
    return el.get_text(strip=True) if el else ""


def parse_article_page(html):
    """ë…¼ë¬¸ í˜ì´ì§€ íŒŒì‹±"""
    soup = BeautifulSoup(html, "html.parser")

    # ì œëª©
    title = extract_text(soup.select_one("span.title-text"))

    # ì €ì
    authors = [extract_text(a) for a in soup.select("div.author-group span.react-xocs-alternative-link")]
    authors = ", ".join([a for a in authors if a])

    # ì´ˆë¡
    abs_el = soup.select_one("div.abstract.author") or soup.select_one("div[id^='sp']") \
             or soup.select_one("div.Abstracts div.abstract")
    abstract = extract_text(abs_el)
    if abstract.lower().startswith("abstract"):
        abstract = abstract[len("abstract"):].strip()

    # í‚¤ì›Œë“œ
    keywords = [extract_text(k) for k in soup.select("div.keywords-section div.keyword > span")]
    if not keywords:
        keywords = [extract_text(k) for k in soup.select("div.Keywords div.keyword")]
    keywords = ", ".join([k for k in keywords if k])

    return title, authors, abstract, keywords


def restart_driver(driver, wait):
    """ë“œë¼ì´ë²„ ì¬ì‹œì‘"""
    try:
        driver.quit()
        print("ğŸ”„ ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì¤‘...")
        random_wait(3, 5)
    except Exception:
        pass

    new_driver = get_driver()
    new_wait = WebDriverWait(new_driver, 30)
    return new_driver, new_wait


def save_progress(rows, filepath):
    """ì§„í–‰ ìƒí™© ì €ì¥"""
    try:
        df = pd.DataFrame(rows)
        df.to_csv(filepath, index=False, encoding="utf-8-sig")
        print(f"ğŸ’¾ ì§„í–‰ ìƒí™© ì €ì¥ë¨ ({len(rows)}ê°œ ë…¼ë¬¸)")
        return True
    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


# ===== í¬ë¡¤ë§ ë©”ì¸ ë¡œì§ =====
def main():
    driver = get_driver()
    wait = WebDriverWait(driver, 30)
    all_rows = []

    # ê¸°ì¡´ ì§„í–‰ ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(OUTPUT_CSV):
        try:
            existing_df = pd.DataFrame(pd.read_csv(OUTPUT_CSV))
            all_rows = existing_df.to_dict('records')
            print(f"ğŸ“‚ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ: {len(all_rows)}ê°œ ë…¼ë¬¸")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

    try:
        for vol in range(vol_from, vol_to + 1):
            toc_url = f"https://www.sciencedirect.com/journal/decision-support-systems/vol/{vol}/suppl/C"
            print(f"\n{'=' * 60}")
            print(f"ğŸ“š [DSS] Volume {vol} í¬ë¡¤ë§ ì‹œì‘")
            print(f"{'=' * 60}")

            # TOC í˜ì´ì§€ ì ‘ì†
            if not safe_get_url(driver, toc_url):
                print(f"âŒ Volume {vol} TOC ì ‘ì† ì‹¤íŒ¨. ê±´ë„ˆë›°ê¸°.")
                continue

            # ì¿ í‚¤ ìˆ˜ë½ (ì²« ë²ˆì§¸ ë³¼ë¥¨ì—ì„œë§Œ)
            if vol == vol_from:
                accept_cookies(driver)

            # ë…¼ë¬¸ ëª©ë¡ ë¡œë”© ëŒ€ê¸°
            try:
                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".text-l")))
                random_wait(2, 3)
            except TimeoutException:
                print(f"âŒ ë…¼ë¬¸ ëª©ë¡ ë¡œë”© ì‹¤íŒ¨: Volume {vol}")
                # ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì‹œë„
                driver, wait = restart_driver(driver, wait)
                continue

            # ë…¼ë¬¸ ë§í¬ ìˆ˜ì§‘
            title_spans = driver.find_elements(By.CSS_SELECTOR, ".text-l")
            if not title_spans:
                print(f"âš ï¸ ë…¼ë¬¸ ë§í¬ ì—†ìŒ: Volume {vol}")
                continue

            hrefs = []
            for el in title_spans:
                try:
                    parent = el.find_element(By.XPATH, "./ancestor::a")
                    hrefs.append(parent.get_attribute("href"))
                except Exception:
                    hrefs.append(None)

            pub_date = get_date_by_volume(vol)
            print(f"ğŸ“… Volume {vol} â†’ Date: {pub_date}")
            print(f"ğŸ“„ ì´ {len(hrefs)}ê°œ ë…¼ë¬¸ ë°œê²¬")

            # ê° ë…¼ë¬¸ í¬ë¡¤ë§
            for idx, href in enumerate(hrefs):
                article_num = idx + 1
                print(f"\n[{article_num}/{len(hrefs)}] ì²˜ë¦¬ ì¤‘...", end=" ")

                retry_count = 0
                success = False

                while retry_count < MAX_RETRIES and not success:
                    try:
                        # ë…¼ë¬¸ í˜ì´ì§€ ì ‘ì†
                        if href:
                            if not safe_get_url(driver, href):
                                raise TimeoutException("URL ì ‘ì† ì‹¤íŒ¨")
                        else:
                            # href ì—†ì„ ê²½ìš° ë‹¤ì‹œ TOC ê°€ì„œ í´ë¦­
                            if not safe_get_url(driver, toc_url):
                                raise TimeoutException("TOC ë³µê·€ ì‹¤íŒ¨")

                            wait.until(EC.presence_of_all_elements_located(
                                (By.CSS_SELECTOR, "span.js-article-title.text-l")))
                            spans = driver.find_elements(By.CSS_SELECTOR, "span.js-article-title.text-l")

                            if idx >= len(spans):
                                print(f"âš ï¸ ì¸ë±ìŠ¤ ì´ˆê³¼")
                                break

                            link = spans[idx]
                            driver.execute_script(
                                "arguments[0].scrollIntoView({behavior:'instant',block:'center'});", link)
                            random_wait(0.8, 1.5)
                            driver.execute_script("arguments[0].click();", link)

                        # ë…¼ë¬¸ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "span.title-text")))
                        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                        random_wait(1.5, 2.5)

                        # ë…¼ë¬¸ ì •ë³´ íŒŒì‹±
                        title, authors, abstract, keywords = parse_article_page(driver.page_source)

                        # ë°ì´í„° ì €ì¥
                        all_rows.append({
                            "volume": vol,
                            "issue": "suppl/C",
                            "date": pub_date,
                            "title": title,
                            "authors": authors,
                            "abstract": abstract,
                            "keywords": keywords,
                            "url": driver.current_url
                        })

                        print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ")
                        success = True

                        # ì£¼ê¸°ì  ì €ì¥ ë° ë“œë¼ì´ë²„ ì¬ì‹œì‘
                        if len(all_rows) % 20 == 0:
                            save_progress(all_rows, OUTPUT_CSV)
                            driver, wait = restart_driver(driver, wait)
                            # TOCë¡œ ë³µê·€
                            safe_get_url(driver, toc_url)
                            wait.until(EC.presence_of_all_elements_located(
                                (By.CSS_SELECTOR, "span.js-article-title.text-l")))
                            random_wait(2, 3)

                    except (StaleElementReferenceException, TimeoutException, WebDriverException) as e:
                        retry_count += 1
                        print(f"ğŸš§ ì˜¤ë¥˜ ë°œìƒ (ì¬ì‹œë„ {retry_count}/{MAX_RETRIES}): {type(e).__name__}")

                        if retry_count < MAX_RETRIES:
                            # TOC ë³µêµ¬ ì‹œë„
                            try:
                                safe_get_url(driver, toc_url)
                                wait.until(EC.presence_of_all_elements_located(
                                    (By.CSS_SELECTOR, "span.js-article-title.text-l")))
                                random_wait(2, 3)
                            except Exception:
                                # ë“œë¼ì´ë²„ ì¬ì‹œì‘
                                driver, wait = restart_driver(driver, wait)
                                safe_get_url(driver, toc_url)
                                try:
                                    wait.until(EC.presence_of_all_elements_located(
                                        (By.CSS_SELECTOR, "span.js-article-title.text-l")))
                                except Exception:
                                    print("âŒ ë³µêµ¬ ì‹¤íŒ¨. ë‹¤ìŒ ë³¼ë¥¨ìœ¼ë¡œ ì§„í–‰.")
                                    break

                        random_wait(3, 5)

                if not success:
                    print(f"âŒ ìµœì¢… ì‹¤íŒ¨: Volume {vol}, Article {article_num}")

            # Volume ì™„ë£Œ í›„ ì €ì¥
            save_progress(all_rows, OUTPUT_CSV)
            print(f"\nâœ… Volume {vol} ì™„ë£Œ!")

    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\n\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
    finally:
        try:
            driver.quit()
        except Exception:
            pass

        # ìµœì¢… ì €ì¥
        save_progress(all_rows, OUTPUT_CSV)

        print(f"\n{'=' * 60}")
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ {len(all_rows)}ê°œ ë…¼ë¬¸ ìˆ˜ì§‘ë¨")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {OUTPUT_CSV}")
        print(f"{'=' * 60}")


if __name__ == "__main__":
    main()